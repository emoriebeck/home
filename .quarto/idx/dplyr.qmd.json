{"title":"Data Manipulation: Intro to `dplyr`","markdown":{"yaml":{"title":"Data Manipulation: Intro to `dplyr`","author":"Emorie D Beck","output":{"html_document":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true}}},"headingText":"`dplyr`","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)\n```\n\n```{r}\nlibrary(psych)\nlibrary(dplyr)\n```\n\nThe `dplyr` package is a powerful set of tools from within the larger `tidyverse` suite of functions. `dplyr` functions are useful for a variety of functions, perhaps particularly data manipulation.  \n\nAlthough there are a large number of functions within the `dplyr` package, today I'm going to introduce a subset of them along with a small number of use cases. But don't worry, these functions will be the key underpinning of code I use in all tutorials going forward, so there will be lots more examples and use cases.  \n\nFor now, here's a quick list of the functions we'll cover today:  \n\n1. `%>%`: The pipe. Read as \"and then.\"  \n2. `filter()`: Pick observations (rows) by their values.  \n3. `select()`: Pick variables (columns) by their names.  \n4. `arrange()`: Reorder the rows.  \n5. `group_by()`: Implicitly split the data set by grouping by names (columns).  \n6. `mutate()`: Create new variables with functions of existing variables.  \n7. `summarize()` / `summarise()`: Collapse many values down to a single summary.  \n\nAlthough each of these functions are powerful alone, they are incredibly powerful in conjunction with one another. So below, I'll briefly introduce each function, then link them all together using an example of basic data cleaning and summary.  \n\n\n# Key `dplyr` Functions  \n\n## 1. `%>%`  \nThe pipe `%>%` is wonderful. It makes coding intuitive. Often in coding, you need to use so-called nested functions. For example, you might want to round a number after taking the square of 43.  \n\n```{r}\nsqrt(43)\n\nround(sqrt(43), 2)\n```\n\nThe issue with this comes whenever we need to do a series of operations on a data set or other type of object. In such cases, if we run it in a single call, then we have to start in the middle and read our way out.  \n\nThe pipe solves this by allowing you to read from left to right (or top to bottom). The easiest way to think of it is that each call of `%>%` reads and operates as \"and then.\" So with the rounded square root of 43, for example: \n\n```{r}\nsqrt(43) %>%\n  round(2)\n```\n\nAs you can see, the two results are the same but the second is slightly easier to follow. And, as you'll see below, this becomes even more intuitive when you start using it in conjunction with `dplyr` functions.  \n\n## 2. `filter()`  \nOften times, when conducting research (experiments or otherwise), there are observations (people, specific trials, etc.) that you don't want to include. \n\nSay for example, that you're interested personality change in adolescence, but you just opened a survey up online. So when you actually download and examine your data, you realize that you have an age range of something like 3-86, not 12-18. In this case, you want to get rid of the people over 18 -- that is, `filter()` them out.  \n\n```{r}\ndata(bfi) # grab the bfi data from the psych package\nbfi <- bfi %>% as_tibble()\n\nsummary(bfi$age) # get age descriptives\n\nbfi2 <- bfi %>% # see a pipe!\n  filter(age <= 18) # filter to age up to 18\n\nsummary(bfi2$age) # summary of the new data \n```\n\nBut this isn't quite right. We still have folks below 12. But, the beauty of `filter()` is that you can do sequence of `OR` and `AND` statements when there is more than one condition, such as up to 18 `AND` at least 12.  \n\n```{r}\nbfi2 <- bfi %>%\n  filter(age <= 18 & age >= 12) # filter to age up to 18 and at least 12\n\nsummary(bfi2$age) # summary of the new data \n```\n\nGot it!  \n\nBut filter works for more use cases than just conditional `<`, `>`, `<=`, and `>=`. It can also be used for cases where we want a single values to match cases with text. Before I demonstrate that, though, I need to convert one of the variables in the `bfi` data frame to a string. So let's change gender (1 = male, 2 = female) to text (we'll get into factors later).  \n\n```{r}\nbfi$education <- plyr::mapvalues(bfi$education, 1:5, c(\"Below HS\", \"HS\", \"Some College\", \"College\", \"Higher Degree\"))\n```\n\nNow let's try a few things: \n\n**1. Create a data set with only individuals with some college (`==`).**  \n\n```{r}\nbfi2 <- bfi %>% \n  filter(education == \"Some College\")\nunique(bfi2$education)\n```\n\n**2. Create a data set with only people age 18 (`==`).**  \n\n```{r}\nbfi2 <- bfi %>%\n  filter(age == 18)\nsummary(bfi2$age)\n```\n\n**3. Create a data set with individuals with some college or above (`%in%`).**  \n\n```{r}\nbfi2 <- bfi %>%\n  filter(education %in% c(\"Some College\", \"College\", \"Higher Degree\"))\nunique(bfi2$education)\n```\n\nThe `%in%` operator is wonderful. Instead of comparing a column to a single value, you can compare it to several. So above, when we wanted ages between 12 and 18, we could have done:  \n\n```{r}\nbfi2 <- bfi %>%\n  filter(age %in% 12:18)\nsummary(bfi2$age)\n```\n\nI've been using `dplyr` for nearly five years, and I still have to remind myself that when you want to remove rows, you use `filter()`.  \n\n## 3. `select()`  \nIf `filter()` is for pulling certain observations (rows), then `select()` is for pulling certain variables (columns). Almost without fail, any data that are received for collected are going to have some variables that are not used, not useful, extraneous, etc. In such cases, it's good practice to remove these columns to stop your environment from becoming cluttered and eating up your RAM. \n\nIn our `bfi` data, most of these have been pre-removed, so instead, we'll imagine we don't want to use any indicators of Agreeableness (A1-A5) and that we aren't interested in gender.  \n\nWith `select()`, there are few ways choose variables. We can bare quote name the ones we want to keep, bare quote names we want to remove, or use any of a number of `select()` helper functions.  \n\n**1. Bare quote columns we want to keep:**  \n```{r}\nbfi %>%\n  select(C1, C2, C3, C4, C5)\n```\n\nI'm going to stop there because I don't want to name the additional 17 columns we want to keep. Instead we'll use `:` to grab a *range* of columns.  \n\n```{r}\nbfi %>%\n  select(C1:O5, education, age)\n```\n\n**2. Bare quote columns we don't want to keep:**  \n\n```{r}\nbfi %>% \n  select(-(A1:A5), -gender)\n```\n\nNote the `()` around the columns. That is necessary when you want to remove a range of columns. \n\n**3. Add or remove using `select()` helper functions.**  \n\n* `starts_with()`: matches names that begin with quoted argument. For example, if we wanted all the Conscientiousness items, we could call the following:  \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"))\n```\n\n* `ends_with()`: matches names that end with quoted argument. For example, if we wanted the first item in each Big Five scale, we could call:  \n\n```{r}\nbfi %>% \n  select(ends_with(\"1\"))\n```\n\n* `contains()`: matches names that contain quote material. This can be any subset of a string, which makes it very useful for a number of contexts we'll see later. But for now, if I wanted to be lazy or couldn't remember the name of th education variable, I could call:  \n\n```{r}\nbfi %>% \n  select(contains(\"edu\"))\n```\n\n* `matches()`: selects variables that match a regular expression (regex). Regex is tricky. I tend to end up referencing online documentation when I need to use this beyond a few basic expressions that I use very regularly. We'll start with a simple one, keeping only those variables that either have or do not have numbers:   \n\n```{r}\n# contains numbers\nbfi %>%\n  select(matches(\"[0-9]\")) \n\n# does not contain numbers\nbfi %>%\n  select(!matches(\"[0-9]\")) \n```\n\n* `num_range()`: Given a stem and a range of numbers, this selects items in a sequence. This is especially useful when variables of your data set may not be in order.  \n\n```{r}\n# select first 2 Extraversion items\nbfi %>%\n  select(num_range(\"E\", 1:2))\n```\n\n* `one_of()`: select any of a subset of items from a vector. This is one of my favorites, for reasons we'll see in my tutorial on workflow and data documentation. But for now, let's say I thought there were six items in each personality when there are actually five. So when I call the following, `one_of()` will be forgiving and ignore the fact that I messed up.  \n\n```{r}\nbfi %>% \n  select(one_of(paste0(\"E\", 1:6)))\n```\n\n* `all_of()`: select all of a subset of items from a vector. Unlike `one_of()`, `all_of()` is less forgiving and will throw an error if we try to call for 6 Extraversion items.  \n\n```{r, error=TRUE}\nbfi %>%\n  select(all_of(paste0(\"E\", 1:6)))\n```\n\nOops. In this case, we'd then need to modify the code to reflect the correct number of items.  \n\n```{r}\nbfi %>%\n  select(all_of(paste0(\"E\", 1:5)))\n```\n\n## 4. `arrange()` \nSometimes, either in order to get a better sense of our data or in order to well, order our data, we want to sort it. Although there is a base `R` `sort()` function, the `arrange()` function is `tidyverse` version that plays nicely with other `tidyverse functions`. \n\nSo in our previous examples, we could also `arrange()` our data by age or education, rather than simply filtering. (Or as we'll see later, we can do both!)  \n\n```{r}\n# sort by age\nbfi %>% \n  select(gender:age) %>%\n  arrange(age)\n\n# sort by education\nbfi %>%\n  select(gender:age) %>%\n  arrange(education)\n```\n\nWe can also arrange by multiple columns, like if we wanted to sort by gender then education:  \n\n```{r}\nbfi %>%\n  select(gender:age) %>%\n  arrange(gender, education)\n```\n\n\n# Bringing it all together: Split-Apply-Combine  \nMuch of the power of `dplyr` functions lay in the split-apply-combine method. The method is kind of what it sounds like. A given set of of data are *split* into smaller chunks, then a function or series of functions are *applied* to each chunk, and then the chunks are *combined* back together. \n\nAlthough all of the `dplyr` functions can be used in conjunction with one another, I'm going to highlight the `group_by()`, `mutate()`, and `summarize()` / `summarise()` functions to highlight the core of the split-apply-combine method.  \n\n## 5. `group_by()`  \n\nThe `group_by()` function is the \"split\" of the method. It basically implicitly breaks the data set into chunks by whatever bare quoted column(s)/variable(s) are supplied as arguments.  \n\nSo imagine that we wanted to `group_by()` education levels to get average ages at each level. We would simply call: \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education)\n```\n\nWe can now see that it tells us that we have a tibble with 2,800 rows and 8 columns as well as `Groups:   education [6]`  \n\nImportantly, once you group, you must `ungroup()` or your data frame will remain \"split\" and cause you problems. In other words, you must \"combine\" your data frame back together. This is super easy with the `ungroup()` function:  \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education) %>%\n  ungroup()\n```\n\nYou can also overwrite groups by calling `group_by()` more than once. We'll touch more on that in future tutorials, but for now, notice what happens when I call `group_by()` twice sequentially:  \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  group_by(education) %>%\n  group_by(gender, age)\n```\n\nNote that the resulting data frame is not grouped by education at all, but by gender and age (i.e. it is not cumulative).  \n\n## 6. `mutate()`  \n\nThe `mutate()` function is one of a few options for how to \"apply\" (a) function(s) to your split (i.e. `group_by()`) data frame. When you use `mutate()`, the resulting data frame will have the same number of rows you started with (which will not be true with `summarize()` / `summarise()`). One way to remember is this is that you are directly mutating the existing data frame, either modifying existing columns or creating new ones. \n\nSo to continue with the example above, if we were to add a column that indicated average age levels within each age group, we would call:  \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  group_by(education) %>% \n  mutate(age_by_edu = mean(age, na.rm = T))\n```\n\nAs you can see in the resulting data frame, each person (row) with the same education level has the same value in the new `age_by_edu` column I just added.  \n\n`mutate()` is also super useful even when you aren't grouping. For example, if I wanted to recode gender so that 1 = \"male\" and 2 = \"female,\" we could do that like: \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  mutate(gender_cat = plyr::mapvalues(gender, c(1,2), c(\"Male\", \"Female\")))\n```\n\nWe could also just write over the original gender category like:  \n\n```{r}\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  mutate(gender = plyr::mapvalues(gender, c(1,2), c(\"Male\", \"Female\")))\n```\n\n\n## 7. `summarize()` / `summarise()`  \n\nThe `summarize()` / `summarise()` functions (choose your spelling as you will) is another of the options for how to \"apply\" (a) function(s) to your split (i.e. `group_by()`) data frame. When you use `summarize()` (I made by choice), the resulting data frame will have the number of rows equal to the number of `group_by()` categories you provide. So if you provided `education`, that will be 6, and if you provided none, it would be one.  \n\n```{r}\n# group_by() education\nbfi %>%\n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  group_by(education) %>% \n  summarize(age_by_edu = mean(age, na.rm = T))  \n\n# no groups  \nbfi %>% \n  select(starts_with(\"C\"), age, gender, education) %>%\n  arrange(education) %>%\n  summarize(age_by_edu = mean(age, na.rm = T))  \n```\n\nFrom this, for example, it becomes clear that all the `NA`s in the `education` variable were because they reflected 18 year olds who had not yet completed high school as well as that the sample is pretty young overall.  \n\n# Conclusion  \n\nThis has been a quick and relatively low level introduction into some of the core functions in the `dplyr` package. I challenge you to try to take what you learned and apply it to some of your own data.  \n\nIn the next tutorial, we will touch on data wrangling, introducing the `tidyr` packages. This will provide methods for changing the shape for your data, which, in turn, will open up new opportunities to use `dplyr` functions in useful ways. We will then take all of that and roll it into additional packages and tools.  \n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"html_document":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"dplyr.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","csl":"apa-cv.csl","bibliography":["mybib.bib"],"editor":"visual","theme":"cosmo","title":"Data Manipulation: Intro to `dplyr`","author":"Emorie D Beck"},"extensions":{"book":{"multiFile":true}}}}}