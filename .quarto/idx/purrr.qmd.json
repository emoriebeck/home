{"title":"Intro to `purrr`","markdown":{"yaml":{"title":"Intro to `purrr`","author":"Emorie D Beck","output":{"html_document":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true}},"editor_options":{"chunk_output_type":"console"}},"headingText":"`purrr`","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = F, warning = F, cache = F)\n```\n\n<a href=\"https://raw.githubusercontent.com/emoriebeck/R-tutorials/master/05_purrr/purrr_tutorial.Rmd\" download>Download .Rmd (won't work in Safari or IE)</a>  \n<a href=\"https://github.com/emoriebeck/R-tutorials/tree/master/05_purrr\" target=\"_blank\">See GitHub Repository</a>  \n\nIn my opinion, purrr is one of the most underrated and under-utilized `R` packages. \n\n#Background: iteration\nIteration is everywhere. It underpins much of mathematics and statistics. If you've ever seen the $\\Sigma$ symbol, then you've seen (and probably used) iteration. \n\nIt's also incredibly useful. Anytime you have to repeat some sort of action many times, iteration is your best friend. In psychology, this often means reading in a bunch of individual data files from an experiment, repeating an analysis with a series of different predictors or outcomes, or creating a series of figures. \n\n```{r}\nlibrary(psych)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(plyr)\nlibrary(tidyverse)\n```\n\n\nEnter `for` loops. `for` loops are the \"OG\" form of iteration in computer science. The basic syntax is below. Basically, we can use a for loop to loop through and print a series of things.\n\n```{r}\nfor(i in letters[1:5]){\n  print(i)\n}\n```\n\nIn psychology, we deal with all sorts of weird sorts of data frames. From longitudinal data with separate files for each year to experimental data with separate data for each participant (if you're \"lucky,\" you might even get both!), data are often stored as separate files. THe good news is that `for` loops are here to save you from:  \n\n<ol>\n<li>Writing code to load in each file separately (not good).</li>\n<li>Copying each data file into one larger data set in Excel (worse)</li>\n</ol>\n\nAssuming you have all the data in a single folder and the format is reasonably similar, you have the following basic syntax:  \n\n```{r, eval = F}\ndata_path <- \"\"\nfiles <- list.files(data_path)\ndata <- list()\nfor(i in files){\n  data[[i]] <- read.csv(i, stringsAsFactors = F)\n}\ndata <- combine(data)\n```\n\nThe loop above defines the path of the data, reads all the files in that path, creates an empty list to store the data files, loops through each of the files individually and saves them into the list, and combines each of the read data files into a single data frame.  \n\nThis is all well and good and would work just fine. But what happens if you have multiple data files for different subjects if, say, they complete a writing task and a memory task? Or maybe you work with longitudinal data, like I do, and frequently have multiple data files for a given year for different categories (e.g. health, psychological, etc.). In that case, the loop above might not work. The files might have different properties or be stored in different locations (for your own sanity).  \n\n```{r, eval = F}\ndata_path <- \"\"\ndirectories <- list.files(data_path)\nfiles <- c(\"health\", \"person\")\ndata <- data.frame\nfor(i in directories){\n  for(k in files){\n    tmp <- read.csv(sprintf(\"%s/%s/%s.csv\", data_path, i, k), stringsAsFactors = F)\n    tmp$file <- k\n    data <- bind_rows(data, tmp)\n  }\n}\n```\n\nIn this case, it's a little more complicated. First, our method for loading each of the files into a list doesn't work nicely here because we are iterating through 2 variables. As a result, we have to save each file into an object called \"tmp\" that then must be joined with data from previous iterations. The downside of this is that we have to use a sort of \"brute-force\" method to do so, which is not ideal. Things go wrong with data collection quite often, meaning that files are likely to have different columns. Third, when a loop fails, it refuses to continue. And you are left with a couple of variables (i and k) and have to try to work backward to figure out what is going wrong.  \n\nSound annoying? Enter `purrr`.  \n\n#The purrr solution\npurrr is my favorite alternative to iteration. (There's also the whole `apply` family, which is definitely worth learning -- even I still use it -- but I find `purrr` to be much more useful in the long run.) `purrr` keeps me organized by keeping everything together in a single object. It works nicely with functions like `possibly()` and `safely()` that catch and handle errors. \n\n`purrr` can be used for many more things than I will talk about here. If you want to know more, you can check out Hadley Wickham's [R for Data Science](https://r4ds.had.co.nz/) or `purrr` documentation. I'm going to focus on how *I* I use `purrr`: reading data, cleaning, running models, making tables, and making plots.  \n\nHere's some `purrr` syntax I won't explain now. It's set up to mirror the demonstration above. It will make way more sense soon, I promise: \n\n```{r, eval = F}\nread_fun <- function(pid, dir){\n  sprintf(\"%s/%s/%s.csv\", data_path, dir, pid) %>% read_csv\n}\n\ndata_path <- \"\"\nfile <- list.files(data_path)\ndata <- tibble(file = file) %>%\n  mutate(file = str_remove_all(file, \".csv\")) %>% \n  separate(file, c(\"PID\", \"directory\"), sep = \"_\") %>%\n  mutate(data = map2_df(PID, directory, read_fun)) %>% \n  unnest(data, .drop = T)\n```\n\nBeyond \"WTF\", your initial response may be \"this is not more efficient than the nested `for` loop you showed us above.\" You are partially correct. The rest of the tutorial will be showing you why being wrong now will sooooo right later!  \n\n\n## Nested Data Frames\nBefore we can learn how to use `purrr`, we need to understand what a nested data frame is. If you've ever worked with a list in R, you are halfway there. Basically a nested data frame takes the normal data frame you are probably familiar with and adds some new features. It still has columns, rows, and cells, but what makes up those cells isn't restrictred to numbers, strings, or logicals. Instead, you can put essentially anything you want: lists, models, data frames, plots, etc! \n\nIf that freaks you out a bit, imagine this. Imagine you are me: you work with personality data and want to use each of the Big 5 to individually predict some outcomes, like health and life satisfaction. \n\n\n```{r}\nipip50 <- read.csv(url(\"https://media.githubusercontent.com/media/emoriebeck/R-tutorials/master/05_purrr/ipip50_sample.csv\"), stringsAsFactors = F)\n\n# let's recode the exercise variable (exer)\n# 0 = \"veryRarelyNever\"; 1 = \"less1mo\"; 2 = \"less1wk\"; 3 = \"1or2wk\"; 4 = \"3or5wk\"; 5 = \"more5wk\"\nipip50 <- ipip50 %>% \n  mutate(exer = mapvalues(exer, unique(exer), c(3,4,0,5,2,1)))\n\n```\n\n\nThe really bad solution would be to write the code to model these data, make a table of the results, and make a plot. Then you would copy and paste that code 9 times to do the same steps for the other trait-outcome pairs, changing the key variables. Sometime later, you could run those individually.\n\nA better solution would be a loop, where you use a nested loop to complete the steps for each trait-outcome pair. How you store these values can be a little wonky and often involes a bunch of different lists or a cluttered global environment with losts of objects.   \n\nBut the best solution is purrr. What does this look like? Well, we start with a nested data frame. To do that, we need to make sure our data is ready. I've found that the easiest way to work with data with purrr is to first convert your data to long form, where we want to have columns for all the variable we would want to iterate through in a loop. To help you understand what that means and looks like, I think it's useful to start with a non-nested data frame created by the `crossing()` function from the `dplyr` package. \n\nBasically, `crossing()`  takes what you give it and returns a data frame with all combinations of the variables. There is no limit to the number of columns this can have. Here, we feed it \"Trait\", which contains a vector of the Big 5, and \"Outcome\", which contains a vector of our outcomes, which results in a data frame with 2 columns and 10 rows. \n\n```{r}\n(df <- expand.grid(\n  Trait = c(\"E\", \"A\", \"C\", \"N\", \"O\"),\n  Outcome = c(\"BMI\", \"logMedInc\", \"exer\")\n)) \n```\n\n\nOne cool thing this will allow us to do is to use consistent variable names in formulas and functions and to feed the correct data into different programs using the `dplyr` helper function `filter()`. You can use expand grid with purrr functions without nesting any data in the data frame (in fact, I do this a lot because I work with large data sets and lots of combinations), but I'm going to show you the nested data frame route in this case and refer you to my GitHub for when and how you would use the `crossing()` approach.\n\nBack to nested data frames. We want to end up with a data frame that has the same columns as the `crossing()` data frame except that we want an additional column that holds the data for each trait-outcome pair. To do this, we need to have a column that indexes both trait and outcome. To get this, we change our data to the \"tidy\" format using `gather()` in the `tidyr` package.  \n\nSo let's take our Big 5 data and do that.\n\n```{r}\n# Let's make the trait data long and create composites\n(ipip50_composites <- ipip50 %>%\n  gather(key = item, value = value, A_1:O_10) %>%\n  separate(item, c(\"Trait\", \"item\"), sep = \"_\") %>%\n  group_by(RID, gender, age, BMI, exer, logMedInc, Trait) %>%\n  summarise(t.value = mean(value, na.rm = T)))\n\n# Now let's make the outcomes long\nipip50_composites <- ipip50_composites %>%\n  gather(key = Outcome, value = o.value, BMI:logMedInc) \n```\n\nNow that our data is in long format, we have a couple of options. The first is to use the `nest()` function from the `tidyr` package to chunk our data by trait and outcome. This will result in a data frame with 3 columns: 1 that indexes the Trait, one that indexes the Outcome, and one that indexes the data for that trait and outcome combination. \n\n```{r}\n(ipip50_nested <- ipip50_composites %>% \n  group_by(Trait, Outcome) %>%\n  nest() %>%\n  ungroup())\n```\n\nBasically, instead of the cells in the \"data\" column being a single numeric, logical, or character value, each cell is a data frame! Note that the class of the \"data\" column is a list (hence the name \"list column\") and the class of each cell is a tibble. o_O Pretty cool, huh? Here's why: by putting a data frame of the data for each trait / outcome combination in a single cell, we can operate on each cell like we would a cell in a normal data frame. Sort of.\n\n## The `map()` Functions {.tabset}\nI say sort of because we need another function, this time from the `purrr` package (yay!) called `map()`. Now my purpose here isn't to go through every possible way you can use this. If you want to learn more of the ins and outs see http://r4ds.had.co.nz/many-models.html.  My goal is to show you how I, a psychology grad student, uses purrr every. single. day. in my research.\n\nWhat we want to do is to run a model using personality to predict our outcomes for each combination of trait and outcome. Now that we have a data frame for each nested in a data frame, we're ready to do that. Here's how.  \n\n### `map()`\n```{r}\nstart_time <- Sys.time()\n(ipip50_nested <- ipip50_nested %>%\n  mutate(model = map(data, ~lm(o.value ~ t.value, data = .))))\nend_time <- Sys.time()\nprint(end_time - start_time)\n```\n\nWhat's going on there? Well, we're using `mutate()` from dplyr to create a new column in our data frame called \"model.\" Then, we use the `map()` function to tell it that we want to take each of the cells in the \"data\" column and run a linear model predicting our outcomes (o.value) from personality (t.value). The \"data = .\" part follows because we are within a `dplyr` pipe.  \n\nAs you can see, this results in a new column called \"model.\" As with the data column, the class of the \"model\" column is a list, and the class of any individual cell in the column is the S3 class \"lm\", which just means linear model.  \n\nNow, this is definitely a fast way to run a lot of models, but thus far, this isn't better than a for loop. But our nested data frame can way outperform a for loop. We don't run models just for the sake of doing so. We want to extract the information and report it, often in either a table or figure. With `map()` and `purrr`, we can create a table and figure for each model and *store it in our data frame*. No more dealing with clunky lists whose contents is hard to access or seemingly infinite numbers of objects cluttering your environment. It's all stored in ONE DATA FRAME. (Sorry to shout, but I think the advantages of this cannot be overstated.)\n\nWatch:\n\n```{r}\n(ipip50_nested <- ipip50_nested %>%\n  mutate(tidy = map(model, broom::tidy)))\n```\n\n### `plyr` alternative\nTo be fair, there are other alternative, like `dlply()` in the `plyr` package. I'll demonstrate it below then make a case for why not to do this.  \n\nSo if we start by taking our long format data frame, we can use a very similar format to map to create a list of models.\n```{r}\nmodels <- dlply(ipip50_composites, .(Trait, Outcome), function(x) lm(o.value ~ t.value, data = x))\n```\n\nThen we could again use `tidy()` from `broom` to get summaries.  \n```{r}\ntidies <- llply(models, broom::tidy)\n```\n\nAnd then use `combine()` from `dplyr` to merge them. BUT, we have a problem. (1) We have a weird, nested list, and (2) `combine()` doesn't index our grouping variables like our nested data frame + `map()`.  \n\n### The for Loop Alternative\nOkay, but we can do this with a for loop, so why not? My rationale is that it makes my brain hurt to write a loop that is half as functional the purrr solution. Watch:\n```{r}\nTraits <- c(\"E\", \"A\", \"C\", \"N\", \"O\")\nOutcomes <- c(c(\"BMI\", \"logMedInc\", \"exer\"))\n\nipip50_loop <- list()\ncounter <- 1\nstart_time <- Sys.time()\nfor (trait in Traits){\n  for (outcome in Outcomes){\n    df <- ipip50_composites %>% \n      filter(Trait == trait & Outcome == outcome)\n    tmp <- tibble(Trait = trait, Outcome = outcome)\n    tmp$model <- list(lm(o.value ~ t.value, data = df))\n    ipip50_loop[[counter]] <- tmp\n    counter <- counter + 1\n  }\n}\nend_time <- Sys.time()\nprint(end_time - start_time)\n```\n\nThis took a lot more lines of code and also took longer. For a few models with a small data set, this doesn't matter much. But when you work with hundreds of models with 10's or 100's of thousands of observations, this adds up.  \n\nSo the lesson here is just use `purrr.` Please.\n\n\n## Unnesting\nUsing the `tidy()` function from the `broom` package, we now have another column. Again, the column's class is \"list\" but the cell's class is \"data.frame\". How can we use this? Well, the `nest()` function we used earlier has a sibling called `unnest()`. It does the opposite of `nest()`; it takes our list columns and expands it. So, since we have 2 x 5 data frame in each cell of the \"tidy\" column, when we unnest it, there will be rows for each Trait and outcome combination (where there was only 1 in the nested data frame). This will make more sense with a demonstration:\n\n```{r}\nipip50_nested %>%\n  select(Trait, Outcome, tidy) %>%\n  unnest(tidy)\n```\n\nPretty neat, huh? From here, we may want to do a bunch of different things. And `purrr` is our friend for all of them. I'm going to do a few below, just to show you your options.\n\n## Create a Table\nWhen we have multiple predictors and outcomes, we typically want to smash all this info into a single table, with predictors as different rows of the table and outcomes as different columns (or vice versa). We typically include both an estimate and a confidence interval or standard error for each term in the model (in our case Intercept and t.value).\n\nLet's create a table with different columns for each of the outcomes, and different rows for each trait:\n\n```{r}\n(tab <- ipip50_nested %>%\n  select(Trait, Outcome, tidy) %>%\n  unnest(tidy) %>%\n  select(Trait:std.error) %>%\n  rename(b = estimate, SE = std.error) %>%\n  gather(key = tmp, value = value, b, SE) %>%\n  unite(tmp, Outcome, tmp, sep = \".\") %>%\n  spread(key = tmp, value = value))\n```\n\nWe aren't quite done yet. This table would never make it in a publication. Enter `kable()` + `kableExtra`.\n\n```{r, results = 'asis'}\ntab %>% select(-Trait) %>%\n  kable(., \"html\", booktabs = T, escape = F, digits = 2,\n        col.names = c(\"Term\", rep(c(\"b\", \"SE\"), times = 3))) %>%\n  kable_styling(full_width = F) %>%\n  column_spec(2:7, width = \"2cm\") %>%\n  kableExtra::group_rows(\"Agreeableness\",1,2) %>%\n  kableExtra::group_rows(\"Conscientiousness\",3,4) %>%\n  kableExtra::group_rows(\"Extraversion\",5,6) %>%\n  kableExtra::group_rows(\"Neuroticism\",7,8) %>%\n  kableExtra::group_rows(\"Openness\",9,10) %>%\n  add_header_above(c(\" \" = 1, \"BMI\" = 2, \"Exercise\" = 2, \"Log Median Income\" = 2))\n```\n\nNow I would usually get fancy and bold or flag significant values. I would also use confidence intervals rather than standard errors and add some additional rows with some model summary terms (e.g. $R^2$). If you want to see that, I'll refer you to my github.  \n\n## Plots\n\n### One Big Plot\nSometimes, we want one big plot that shows all our results. What kind of plot? You have choice. Line graphs are popular, but they are perhaps overly simple for these simple linear relationships. We'd also have to go back and get predicted values, which is helpful, but again I'll refer you to my github for more on that. Instead, we're going to create a forest plot, which is useful for determining which terms are different than 0 and how those relate to other terms. We can do this for both our model terms (Intercept and t.value), but I'm going to restrict us to t.value, which tells us how a 1 point increase in a personality characteristic is associated with an outcome.\n\n```{r}\nipip50_nested %>%\n  select(Trait, Outcome, tidy) %>%\n  unnest(tidy) %>%\n  filter(term == \"t.value\") %>%\n  ggplot(aes(x = Trait, y = estimate)) +\n    geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n    geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),\n                  width = .1) +\n    geom_point(aes(color = Trait), size = 3) +\n    coord_flip() +\n    facet_wrap(~Outcome, scale = \"free\") +\n    theme_classic() +\n    theme(legend.position = \"none\")\n```\n\nPretty cool. We see that personality predicts exercise pretty much across the board, but that it does not predict BMI. Only Openness predicts log Median Income.\n\nBut here's where we pat ourselves on the back. We got from nesting our data to the plot above in FIFTEEN LINES OF CODE. Without purrr, it would take us that many lines just to run our models. Then we'd still need to tidy them, join them back together, and plot. I don't want to do that. Or we could use a loop, and create a weird series of lists or a cluttered environment. No thank you on all accounts.  \n\n### Predicted Values\nBut you will encounter times when you want to do predicted values. There are a number of ways to go about this (and both of these ignore that you can just use `geom_smooth()` in the `ggplot2` package with method = \"lm\" for simple linear models). I'm going to show you 2 purrrfect ways. Because demonstrations.  \n\n#### Single Plots\nFirst, let's get predicted values for each model. We'll use `expand.grid()` to get the full range of values for each personality traits (1 to 7) and then use the `predict()` function to get the predicted values, setting the \"newdata\" argument to the newly created range of personality values.  \n\nTo do this, I'm also going to introduce something that is central to `purrr` programming: local functions. As a general rule, if you ever have to do something multiple times, write a function. Save yourself. Please. When writing functions for `purrr`, the basic mindframe I use is to make the inputs of the data frame either the \"data\" column of the nested data frame or the individual columns of interest. So in the function below, I want to get predicted values, so I take a model object as input and output a data frame of predicted values.  \n\n```{r}\npred_fun <- function(mod){\n  crossing(\n    t.value = seq(1,7,.25)\n  ) %>%\n    mutate(pred = predict(mod, newdata = .))\n}\n\n(ipip50_nested <- ipip50_nested %>%\n  mutate(pred = map(model, pred_fun)))\n```\n\nNow, let's take those predicted values and use them to make individual plots.  \n```{r}\nplot_fun <- function(df, trait, outcome){\n  df %>%\n    ggplot(aes(x = t.value, y = pred)) +\n      geom_line() +\n      labs(x = trait, y = outcome) +\n      theme_classic()\n}\n\n(ipip50_nested <- ipip50_nested %>%\n  mutate(plot = pmap(list(pred, Trait, Outcome), plot_fun)))\n```\n\nLet's take a look at how this plot actually looks:  \n```{r}\nipip50_nested$plot[[1]]\n```\n\nMeh, not a fan. Let's do better and combine prediction lines across traits within outcomes. We'll do this two ways: (1) separately for each outcome and (2) using facets across all outcomes.  \n\n```{r}\nipip50_nested %>%\n  unnest(pred) %>%\n  ggplot(aes(x = t.value, y = pred, color = Trait)) +\n    geom_line(size = 2) +\n    facet_wrap(~Outcome, scale = \"free\") +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n```\n\nMeh, this is fine, but the scale's off. This is what I'd call a \"wow graph\" because it exaggerates the differences. I could write some code to put each graph on a realistic scale for the outcome, but for now, I won't.     \n\n```{r, echo = F, eval = F}\nplot_fun <- function(df, outcome){\n  df %>%\n    mutate(Outcome = outcome) %>%\n    ggplot(aes(x = t.value, y = pred, color = Trait)) +\n    geom_line(size = 2) +\n    labs(y = NULL, x = \"Personality Rating (1-7)\") +\n    facet_wrap(~Outcome) +\n    theme_classic() +\n    theme(legend.position = \"bottom\")\n}\n\n(plots <- ipip50_nested %>%\n  unnest(pred) %>%\n  group_by(Outcome) %>%\n  nest() %>%\n  mutate(plot = map2(data, Outcome, plot_fun)))\n\ndo.call(\"grid.arrange\", list(grobs = plots$plot, nrow = 1))\n```\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"html_document":{"code-tools":true,"code-copy":true,"code-line-numbers":true,"code-link":true,"theme":"united","highlight-style":"tango","df-print":"paged","code-fold":"show","toc":true,"toc-float":true}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"purrr.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","csl":"apa-cv.csl","bibliography":["mybib.bib"],"editor":"visual","theme":"cosmo","title":"Intro to `purrr`","author":"Emorie D Beck","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}}}